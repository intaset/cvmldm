<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive">
<meta name="description" content="{{page.meta}}">
<meta name="keywords" content="{{page.keyword}}">
<title>CVMLDM - Identification of Butterfly Species by Similarity Indexes Based on Prototypes</title>

<meta name="handheldfriendly" content="true">
<meta name="mobileoptimized" content="240">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> 
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link href="../css/avestia.css" rel="stylesheet">
<link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic|Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
<link rel="shortcut icon" href="../img/icon.ico" type="image/x-icon">

<!--[if IE-9]><html lang="en" class="ie9"><![endif]-->

<script src="../js/modernizr.custom.63321.js"></script>
<script type="text/javascript" src="../mostvisited.js"></script> 
<script type="text/javascript" src="../mostvisitedExt.js"></script> 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68628727-1', 'auto');
  ga('send', 'pageview');

</script>
<script>
  (function() {
    var cx = '016656741306535874023:izmdhbtn0ey';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
</head>
<body class="loading">
<nav id="slide-menu">
  <h1>Avestia Publishing</h1>
  <ul>
    <li><a href="http://avestia.com/about">About Us</a></li>
    <li><a href="http://avestia.com/ethics">Ethics in Publishing</a></li>
    <li><a href="http://avestia.com/openaccess">Open Access</a></li>
    <li><a href="http://avestia.com/editor">Become a Reviewer or an Editor</a></li>
    <li><a href="http://avestia.com/publishing">Your Publishing Needs</a></li>
    <li><a href="http://avestia.com/proceedings">Conference Proceedings</a></li>
    <li><a href="http://avestia.com/news">Latest News</a></li>
    <li><a href="http://avestia.com/guidelines">Author Guidelines</a></li>
    <li><a href="http://avestia.com/journals">Journals</a></li>
    <li><a href="http://amss.avestia.com/">Submission</a></li>
    <li><a href="http://avestia.com/copyright">Copyright</a></li>
    <li><a href="http://avestia.com/contact">Contact Us</a></li>
  </ul>
</nav>

<div id="content">
  <div class="desktop">
<div class="cbp-af-header">
  <div class="cbp-af-inner grid">
    <div class="unit unit-s-2-8 unit-m-2-8 unit-l-1-7">
      <a href="http://avestia.com"><img src="../img/logo.svg" class="flex-logo" alt="Avestia Publishing"></a>
    </div>

    <div class="unit unit-s-1-2 unit-m-4-0 unit-l-5-1">
    <div class="nav1">
      <nav>
        <a href="http://avestia.com">Home</a>
        <a href="http://amss.avestia.com/">Submission</a>
        <a href="http://avestia.com/journals">Journals</a>
        <a href="http://avestia.com/ethics">Ethics in Publishing</a>
        <a href="http://avestia.com/guidelines">Author Guidelines</a>
      </nav>
    </div>
    </div>

    <div class="unit unit-s-3-4 unit-m-3-5 unit-l-1-6 unit-l-3-2">
    <div class="search-menu">
      <div class="menu-trigger-1"><p class="menu">MENU</p></div><br>
      <gcse:searchbox-only resultsUrl="../results"></gcse:searchbox-only>
    </div>
    </div>

    <div class="unit unit-s-1 unit-m-1 unit-l-1">
    <div class="nav">
      <nav>
        <a href="http://avestia.com">Home</a>
        <a href="http://amss.avestia.com/">Submission</a>
        <a href="http://avestia.com/journals">Journals</a>
        <a href="http://avestia.com/ethics">Ethics in Publishing</a>
        <a href="http://avestia.com/guidelines">Author Guidelines</a>
      </nav>
    </div>
    </div>
  </div>
</div>
  </div>

  <header>
    <div class="mobile">
      <div class="cbp-af-header">
  <div class="cbp-af-inner">
    <div class="unit unit-s-3-4 unit-m-1-3 unit-l-1-3">
          <a href="http://avestia.com"><img src="../img/logo.svg" class="flex-logo" alt="Avestia Publishing"></a>
      </div>
      <div class="unit unit-s-1-3 unit-m-2-3 unit-m-2-3-1 unit-l-2-3">
          <div class="menu-trigger"></div>
      </div>
  </div>
</div>
      <div class="bg">
        <gcse:searchbox-only resultsUrl="../results"></gcse:searchbox-only>
      </div>
    </div> <!-- Mobile -->
  </header>

  <div class="j-header-article">
  <div class="name">
    <h1>International Journal on Computer Vision, Machine Learning, and Data Mining (CVMLDM)</h1>
    <!-- <p class="body">ISSN:</p> -->
    <div class="oalink">
    <a href="http://avestia.com/openaccess" target="blank" title="Avestia's Open Access">
          <img src="../img/j-oa.png" border="0" onmouseover="this.src='../img/j-oa-hover.png'" onmouseout="this.src='../img/j-oa.png'" class="j-oa">
    </a>
    </div>
  </div>
  </div>

  <div role="navigation" class="navbar navbar-default">
  <ul>
    <li><a href="../">Journal Home</a></li>
    <li><a href="../aims">Aims & Scopes</a></li>
    <li><a href="../fee">Publishing Fee</a></li>
    <li><a href="../board">Editorial Board</a></li>
    <li><button data-target=".navbar-collapse" data-toggle="collapse" class="navbar-toggle" type="button">Volumes</button></li>
    <li><a href="../contact">Contact Us</a></li>
  </ul>
  <div class="navbar-collapse collapse">
    <ul class="nav navbar-nav">
      <li><a href="../current">Current Volume</a></li>
    </ul>
  </div><!--/.nav-collapse -->
</div>

<div class="grid">
<div class="unit unit-s-1 unit-m-1 unit-l-1">
  <div class="main-content j-home">
    <div class="unit unit-s-1 unit-s-1-2 unit-m-1-2 unit-l-1-2">
      <p class="body">
      Volume 1 - Year 2015 - Pages 11-19<br>
      DOI: TBD</p>
    </div>

    <div class="unit unit-s-1 unit-s-1-2 unit-m-1-2 unit-l-1-2 a-link">
        <a href="PDF/002.pdf" class="body-link" class="body-link">View PDF (Full-text)</a><br>
      <a href="#references" class="body-link">Linked References</a>
    </div>

    <h3 class="center">Identification of Butterfly Species by Similarity Indexes Based on Prototypes</h3>

    <p class="body-bold center">Ertuğrul Ömer Faruk<sup>1*</sup>, Kaya Yılmaz<sup>2</sup>, Kayci Lokman<sup>3</sup>, Tekin Ramazan<sup>4</sup></p>
    <p class="body center"><sup>1</sup>Department Electrical and Electronic Engineering, Batman University, 72060 Batman, Turkey<br>
    omerfarukertugrul@gmail.com<br>
    <sup>2</sup>Department of Computer Engineering, Siirt University, 56100 Siirt, Turkey<br>
    <sup>3</sup>Department of Biology, Siirt University, 56100 Siirt, Turkey<br>
    <sup>4</sup>Department of Computer Engineering, Batman University, 72060 Batman, Turkey</p>

    <p class="body"><b>Abstract</b> - <i>Butterflies can be classified by their outer morphological qualities, genital characters that can be obtained using various chemical substances and methods, which are carried out manually by preparing genital slides through some certain processes or molecular techniques. The aim of this study is to evaluate a computer vision and machine learning system that correctly identify butterfly species easier, faster and cheaper than traditional methods. In this study, human vision based image similarity methods were used as feature extractors, which were structural similarity measure (SSIM) method that depends on the combination of luminance, contrast and structural comparisons, and feature similarity index (FSIM) method that depends on combination of phase congruency and image gradient magnitude. First of all a prototype was determined for each species of 19 species, then for each butterfly, the SSIM and FSIM indexes were computed. The machine learning methods had achieved high accuracy rates for identification of butterfly species by these indexes, while it achieved 100% accuracy logistic linear classifier method The accuracy results of using SSIM and FSIM as a feature extraction method were compared with other similarity methods such as peak-signal-to-noise ratio, scale invariant feature transform, histogram comparison, image spatiogram comparison and texture methods.</i></p>

    <p class="body"><b><i>Keywords:</i></b> Butterfly identification; similarity; prototype; machine learning methods; SSIM; FSIM; image processing.</p>

    <p class="body">© Copyright 2015 Authors - This is an Open Access article published under the <a href="http://creativecommons.org/licenses/by/3.0" class="body-link" target="_blank">Creative Commons Attribution License terms</a>. Unrestricted use, distribution, and reproduction in any medium are permitted, provided the original work is properly cited.</p>

    <p class="body">Date Received: 2014-07-12<br />
    Date Accepted: 2015-01-08<br>
    Date Published: 2015-01-15</p>

  <div class="border"></div>

  <div class="indent">
  
  <h4>1. Introduction</h4>

<p class="body">The Lepidoptera that involves butterflies and
moths is one of the richest teams among insects with its more than 170.000
species [1]. Traditionally, butterflies have distinguished into species by
their physical properties such as shapes of wings, textures, color, the figures
on wings, taxonomic characters of species or especially the examination of
genitals organs’ outer structural features of male [1] and also molecular
studies can be used for identification [2]. Despite their safety and efficacy,
traditional methods suffer from several major drawbacks: they are difficult,
time-consuming and may be too expensive [3-6]. Additionally, all these studies
used for butterfly identifications do not always give accurate results. Kaya et
al. presented that the butterflies can also be classified by using image
processing and machine learning method as an alternative to conventional diagnostic
methods. In their studies, they employed Gabor filters (GF), grey-level
co-occurrence matrix (GLCM) and local binary pattern (LBP) with various machine
learning methods [3-6] such as multinomial logistic regression (MLR),
artificial neural network (ANN) and extreme learning machine (ELM). However,
texture methods have a number of limitations; they are slow and it is difficult
to determine the optimum parameters for these methods, such as the angle and
distance in GLCM. </p>

<p class="body">In this study, a prototype, human learning based
method [7, 8], were used. The human learns by simplifying the complex
environment and various stimuli with: (a) categorization by grouping the
objects or stimuli that have some common physical or functional traits, (b)
defining an ideal exemplar as a prototype that sums up the characteristics of
members of the category or, (c) rules to better control or understands, (d)
defining an ideal exemplar as a prototype that sums up the characteristics of
members of the category [9, 10].  Osherson and Smith reported that the
prototypes are stored in human memory, to form category definitions [11, 12].
As a summary, using prototypes in place of the whole dataset reduces the
storage and computational cost requirements [13]. </p>

<p class="body">Once, optimum prototypes for each species
determined the similarity measures that are simpler therefore faster than image
texture methods, were used to score the similarity indexes of query with each
prototype. The structural similarity measure (SSIM) [14-19], feature similarity
index (FSIM) [20], peak-signal-to-noise ratio (PSNR) [19], scale invariant
feature transform (SIFT) [21], histogram comparison (HISTC) [22] and image
spatiogram comparison (SPATC) [23] methods were used as a similarity measure.
In this study, employing the SSIM and FSIM similarity measures was assessed in
detailed and the others were used for comparison. </p>

<p class="body">SSIM, which is also called single scale structural
similarity, is a combination of luminance, contrast and structural comparisons
of the images. It was reported that, SSIM can be used for determining the
similarity index between two images that same resolution, perceptual capacity
of the visual system, sampling density of the image, distance of the image
plane to the observer and also it is insensitive to scaling, rotating and
translation of each image [14, 15, 17 and 18]. Therefore, to overcome these
drawbacks multi-scale SSIM was proposed. It was presented that, it is not
sensitive to resolution, perceptual capacity of the visual system, sampling
density of the image and distance from image plane to the observer of an image
[14, 17]. Additionally, the complex wavelet structural similarity (CW-SSIM) was
proposed to calculate the similarity index of images that have different
geometric distortions and lighting conditions by analyzing images at complex
wavelet domain [18]. SSIM was generally used for image quality calculations
[14, 15, 17 and 19], perceptual image coding method by maximum and minimum SSIM
criterion [16] and classification [18].  In this study, the basic SSIM method
was employed, because the butterfly images had the same conditions, such as:
resolution, perceptual capacity of the visual system, sampling density of
image, the distance of the image plane to observer. In 2011, Zhang et al.
proposed FSIM for image quality analysis [20]. The FSIM index is calculated by
phase congruency (PC), which is based on human vision system that the
similarities are analyzed through the points that their Fourier components are
maximal in phase rather than sharp changes in intensity of images [20]. </p>

<p class="body">The aim of this study is to design a computer
vision and machine learning system that correctly identify butterfly species
easier, faster and cheaper than traditional methods and image texture methods.
To our knowledge, there isn’t any study in the literature to identify the
butterfly species by using similarity measures. In this study, SSIM and FSIM
similarity methods were used as a feature extracting features and machine
learning methods were used for butterfly species identification. Obtained
classification accuracies of employing SSIM and FSIM were compared with other
similarity methods; PSNR, SIFT, HISTC and SPATC. As a result, this study showed
that SSIM or FSIM similarity methods with logistic linear classification machine
learning method were very successful for butterfly classification with 100%
classification accuracy. The rest of the paper was organized as follows. The
material and similarity measures used in this study were explained in the next
section. Additionally the procedure of employing the proposed method was
described briefly. Results and discussions are provided in Section 3, while
Section 4 concludes the paper.</p>

<h4>2. Material and Method</h4>

<p class="subhead">2.1. Dataset</p>

<p class="body">In this study species,
belonging to family Papilinidae, was collected from Mount Erek, Van between May
2002 and August 2003 and the altitudes of 1800-3200 meters by the third author.
The dataset generation process was described detailed in our previous studies
[3-6]. The dataset was consisted of 19 species and 10 images of each species.
The determined prototypes for each butterfly species are shown in Figure 1.</p>

<h3>2.2. Similarity Measures</h3>

<p class="body">The similarity measures,
statistical variables, were used for extracting features to increase accuracy,
generalize capacity and stability of the machine learning system while decrease
computational cost.</p>

<p class="body">Structural Similarity
Measure (SSIM) is calculated by analyzing luminance, contrast and structural
comparison of two images. The single scale SSIM [14, 15], which is useful for similarity
measurement between two images that has same conditions such as scale, distance
between object and observer, is in Equation 1.</p>

<figure>
<img src="002_files/image001.jpg" class="article-img">

<figcaption>
Figure
1. The selected samples from nineteen butterflies species.</figcaption>
</figure>

<div class="equation">
<img src="002_files/image002.png" class="eqn">
<div class="eqn-number">(1)</div>
</div>

<p class="body">where;</p>

<ul><li><img src="002_files/image003.png"> is the luminance comparison function;</li></ul>

<div class="equation">>
<img src="002_files/image004.png" class="eqn">
<div class="eqn-number">(2)</div>
</div>

<p class="body">where; <img src="002_files/image005.png">, <img src="002_files/image006.png"> is a small constant <img src="002_files/image007.png">) and <img src="002_files/image008.png"> is a dynamic
range of pixel values.</p>

<ul><li><img src="002_files/image009.png"> is the contrast comparison function;</li></ul>

<div class="equation">>
<img src="002_files/image010.png" class="eqn">
<div class="eqn-number">(3)</div>
</div>

<p class="body">where; <img src="002_files/image011.png">, <img src="002_files/image012.png"> is a small constant (<img src="002_files/image013.png">) and <img src="002_files/image008.png"> is a dynamic
range of pixel values.</p>

<ul><li><img src="002_files/image014.png"> is the structure comparison function;</li></ul>

<div class="equation">>
<img src="002_files/image015.png" class="eqn">
<div class="eqn-number">(4)</div>
</div>

<p class="body">where <img src="002_files/image016.png"> and <img src="002_files/image017.png">, <img src="002_files/image018.png"> and <img src="002_files/image019.png">, which are
used for the relative importance of luminance, contrast and structural
comparisons function, are <img src="002_files/image020.png"> and <img src="002_files/image021.png">. </p>

<p class="body">If <img src="002_files/image022.png"> then equation 1 becomes;</p>

<div class="equation">>
<img src="002_files/image023.png" class="eqn">
<div class="eqn-number">(5)</div>
</div>

<p class="body">where <img src="002_files/image024.png"> are images, <img src="002_files/image025.png"> is the mean intensity (<img src="002_files/image026.png">), <img src="002_files/image027.png"> is the standard deviation as an estimate of
signal contrast (<img src="002_files/image028.png">) and <img src="002_files/image029.png"> is relative standard deviation (<img src="002_files/image030.png">.</p>

<p class="body"><b>Feature Similarity Index (FSIM)</b> depends on PC
and image GM parameters [20]. The images are firstly filtered by 2D Gabor
filter is:</p>

<div class="equation">>
<img src="002_files/image031.png" class="eqn">
<div class="eqn-number">(6)</div>
</div>

<p class="body">where <img src="002_files/image032.png"> and <img src="002_files/image033.png"> is the number of orientation and <img src="002_files/image034.png"> is filter’s angular bandwidth. FSIM is calculated
as follows.</p>

<div class="equation">>
<img src="002_files/image035.png" class="eqn">
<div class="eqn-number">(7)</div>
</div>

<p class="body">where <img src="002_files/image036.png"> is whole image spatial domain, <img src="002_files/image037.png"> which is the weight of similarity <img src="002_files/image038.png">.</p>

<div class="equation">>
<img src="002_files/image039.png" class="eqn">
<div class="eqn-number">(8)</div>
</div>

<div class="equation">>
<img src="002_files/image040.png" class="eqn">
<div class="eqn-number">(9)</div>
</div>

<p class="body">where <img src="002_files/image041.png"> is phase congruency (PC) function <img src="002_files/image042.png"> and <img src="002_files/image043.png"> is image gradient magnitude (GM) function <img src="002_files/image044.png">, where <img src="002_files/image045.png"> and <img src="002_files/image046.png"> are positive constants for stability and Gradient
Magnitude of an image is calculated by using Sobel, Prewitt and Scharr gradient
operators’ partial derivatives <img src="002_files/image047.png"> and <img src="002_files/image048.png"> of the image <img src="002_files/image049.png">. PC is:</p>

<div class="equation">>
<img src="002_files/image050.png" class="eqn">
<div class="eqn-number">(10)</div>
</div>

<p class="body">where <img src="002_files/image051.png"> <img src="002_files/image052.png"> is the local energy along the orientation <img src="002_files/image053.png">, and <img src="002_files/image054.png"> (<img src="002_files/image055.png">, where <img src="002_files/image056.png"> are response of point <img src="002_files/image057.png"> on scale <img src="002_files/image058.png">) is the local
amplitude on scale <img src="002_files/image058.png"> and
orientation <img src="002_files/image053.png">.</p>

<p class="subhead">2.3. Procedure of
Butterfly Identification Process</p>

<p class="body">For the purpose of butterfly identification, the
procedure of butterfly identification process is shown in Figure 2.</p>

<figure>
<img src="002_files/image059.png" class="article-img">

<figcaption>
Figure 2.
The Procedure of Butterfly Identification.</figcaption>
</figure>

<p class="body">As seen in Figure 2, first of all, a prototype for
each species was determined. These prototypes are determined by selecting the
images which belonged higher similarity indexes between this image and other
images. After determining the best “prototype” for each species, SSIM and FSIM
indexes were calculated for each image with prototype images. A feature vector
for each image with 19x1 sized, whose values are between 0 and 1, is
determined. Finally, the machine learning methods were used to identify images.
The machine learning methods used in this study were linear (built on the kl
expansion of the common covariance matrix), linear (using pc expansion on the
joint data), logistic linear, fisher least square linear, nearest mean, nearest
mean scaled, linear perceptron, subspace, linear bayes, k-nearest neighbor,
parzen, parzen density based, naive bayes, support vector, support vector
classifier (nu algorithm) and arbitrary kernel/dissimilarity based classifier
methods.</p>

<h4>3. Results and Discussion</h4>

<p class="body">The classification
accuracies were computed by the mean of 10 folds cross-validation. All the work
on the computer was carried out using an Intel Core i7-2600 CPU, 3.4 GHz, 4 GB
RAM, PC. An image and the obtained SSIM (&#945;=&#946;=&#947;=1) and FSIM (&#945;=&#946;=1)
similarity indexes of this image with prototype images are shown in Figure 3
and Figure 4, respectively.</p>

<p class="body">Note that the sample image
belongs to Anthocharis cardamines species, which has the highest SSIM and FSIM
indexes with the first image as seen in Figure 3 and 4. Once the dataset was
generated, the classification was done with various classification methods that
have different characteristic. The butterfly classification accuracies (%) and
their standard deviation (STD) is sorted in Table 1. Employed SSIM parameters
are &#945;=&#946;=&#947;=1 and FSIM are &#945;=&#946;=1.</p>

<p class="body">The classification
accuracies in Table 1 showed that the butterfly species can be determined
without any error while employing features that are extracted by SSIM and FSIM
similarity indexes. Additionally, for optimizing the decision support system,
various &#945;, &#946; and &#947; values were assigned and the obtained
classification accuracies were sorted in Table 2 and Table 3. k-Nearest
Neighbor (kNN) was used for classification and performance and k is the
optimized number of nearest neighbor.</p>

<figure>
<img src="002_files/image060.jpg" class="article-img">

<figcaption>
Figure
3. An Image Sample.</figcaption>
</figure>

<center>
<div class="widetable">
<table style="border:none;">
<tbody style="text-align:center">
 <tr style="border:none;">
  <td style="border: none;"><img src="002_files/image061.jpg"></td>
  <td style="border: none;"><img src="002_files/image062.jpg"></td>
  <td style="border: none;"><img src="002_files/image063.jpg"></td>
  <td style="border: none;"><img src="002_files/image064.jpg"></td>
  <td style="border: none;"><img src="002_files/image065.jpg"></td>
 </tr>
 <tr>
 <td style="border:none;">SSIM:1.00<br>FSIM:1.00</td>
 <td style="border:none;">SSIM:0.40<br>FSIM:0.74</td>
 <td style="border:none;">SSIM:0.44<br>FSIM:0.76</td>
 <td style="border:none;">SSIM:0.26<br>FSIM:0.72</td>
 <td style="border:none;">SSIM:0.17<br>FSIM:0.65</td>
 </tr>
 <tr style="border:none;">
  <td style="border: none;"><img src="002_files/image066.jpg"></td>
  <td style="border: none;"><img src="002_files/image067.jpg"></td>
  <td style="border: none;"><img src="002_files/image068.jpg"></td>
  <td style="border: none;"><img src="002_files/image069.jpg"></td>
  <td style="border: none;"><img src="002_files/image070.jpg"></td>
 </tr>
 <tr>
 <td style="border:none;">SSIM:0.31<br>FSIM:0.71</td>
 <td style="border:none;">SSIM:0.29<br>FSIM:0.71</td>
 <td style="border:none;">SSIM:0.28<br>FSIM:0.68</td>
 <td style="border:none;">SSIM:0.27<br>FSIM:0.68</td>
 <td style="border:none;">SSIM:0.33<br>FSIM:0.72</td>
 </tr>
 <tr style="border:none;">
  <td style="border: none;"><img src="002_files/image071.jpg"></td>
  <td style="border: none;"><img src="002_files/image072.jpg"></td>
  <td style="border: none;"><img src="002_files/image073.jpg"></td>
  <td style="border: none;"><img src="002_files/image074.jpg"></td>
  <td style="border: none;"><img src="002_files/image075.jpg"></td>
 </tr>
 <tr>
 <td style="border:none;">SSIM:0.28<br>FSIM:0.69</td>
 <td style="border:none;">SSIM:0.31<br>FSIM:0.71</td>
 <td style="border:none;">SSIM:0.32<br>FSIM:0.71</td>
 <td style="border:none;">SSIM:0.23<br>FSIM:0.70</td>
 <td style="border:none;">SSIM:0.23<br>FSIM:0.70</td>
 </tr>
 <tr style="border:none;">
  <td style="border: none;"><img src="002_files/image076.jpg"></td>
  <td style="border: none;"><img src="002_files/image077.jpg"></td>
  <td style="border: none;"><img src="002_files/image078.jpg"></td>
  <td style="border: none;"><img src="002_files/image079.jpg"></td>
 </tr>
 <tr style="border:none;">
  <td style="border:none;">SSIM:0.66<br>FSIM:0.23</td>
  <td style="border:none;">SSIM:0.67<br>FSIM:0.20</td>
  <td style="border:none;">SSIM:0.72<br>FSIM:0.30</td>
  <td style="border:none;">SSIM:0.74<br>FSIM:0.36</td>
 </tr>
 </tbody>
</table>
<figure>Figure
4. SSIM and FSIM of species’ reference images with the reference image.</figure>
</div>
</center>

<center>
<div class="widetable">
<p class="body">Table
1. Results of Classification.</p>
<table>
<thead>
 <tr>
  <td></td>
  <td>Classification Methods</td>
  <td colspan="4">Feature
  Extraction Method
  </td>
 </tr>
 <tr>
  <td></td>
  <td></td>
  <td colspan="2">SSIM</td>
  <td colspan="2">FSIM</td>
 </tr>
 <tr>
  <td></td>
  <td></td>
  <td>Accuracy(%)</td>
  <td>STD</td>
  <td>Accuracy
  (%)</td>
  <td>STD</td>
 </tr>
</thead>
 <tbody>
 <tr>
  <td>1</td>
  <td>Linear
  classifier built on the KL expansion of the common covariance matrix</td>
  <td>98,95</td>
  <td>0,64
  </td>
  <td>99,26
  </td>
  <td>0,47</td>
 </tr>
 <tr>
  <td>2
  </td>
  <td>Linear
  classifier using PC expansion on the joint data
  </td>
  <td>98,4
  </td>
  <td>0,98  </td>
  <td>99,1
  </td>
  <td>0,47  </td>
 </tr>
 <tr>
  <td>3</td>
  <td>Logistic
  Linear Classifier
  </td>
  <td>100,00
  </td>
  <td>0,00
  </td>
  <td>100,00
  </td>
  <td>0,00
  </td>
 </tr>
 <tr>
  <td>4
  </td>
  <td>Fisher
  Least Square Linear Classifier
  </td>
  <td>99,89
  </td>
  <td>0,24
  </td>
  <td>99,37
  </td>
  <td>0,24
  </td>
 </tr>
 <tr>
  <td>5
  </td>
  <td>Nearest
  Mean Classifier
  </td>
  <td>96,42
  </td>
  <td>1,84
  </td>
  <td>98,32
  </td>
  <td>0,58
  </td>
 </tr>
 <tr>
  <td>6
  </td>
  <td>Nearest
  Mean Scaled Classifier
  </td>
  <td>95,47
  </td>
  <td>1,09
  </td>
  <td>97,89
  </td>
  <td>0,64
  </td>
 </tr>
 <tr>
  <td>7
  </td>
  <td>Linear
  Perceptron Classifier
  </td>
  <td>97,05
  </td>
  <td>0,80
  </td>
  <td>96,11
  </td>
  <td>0,29
  </td>
 </tr>
 <tr>
  <td>8
  </td>
  <td>Subspace
  Classifier
  </td>
  <td>97,05
  </td>
 <td>0,47
  </td>
 <td>98,21
  </td>
 <td>0,29
  </td>
 </tr>
 <tr>
  <td>9
  </td>
  <td>Linear
  Bayes Classifier
  </td>
  <td>98,42
  </td>
  <td>0,83
  </td>
  <td>99,47
  </td>
  <td>0,00
  </td>
 </tr>
 <tr>
  <td>10
  </td>
  <td>k-Nearest
  Neighbor Classifier
  </td>
  <td>99,16
  </td>
  <td>0,29
  </td>
  <td>98,84
  </td>
  <td>0,44
  </td>
 </tr>
 <tr>
  <td>11
  </td>
  <td>Parzen
  Classifier
  </td>
  <td>98,84
  </td>
  <td>0,24
  </td>
  <td>98,84
  </td>
  <td>0,24
  </td>
 </tr>
 <tr>
  <td>12
  </td>
  <td>Parzen
  Density Based Classifier
  </td>
  <td>97,79
  </td>
  <td>0,69
  </td>
  <td>97,05
  </td>
  <td>0,88
  </td>
 </tr>
 <tr>
  <td>13
  </td>
  <td>Naive
  Bayes Classifier
  </td>
  <td>92,11
  </td>
  <td>0,64
  </td>
  <td>95,05
  </td>
  <td>0,80
  </td>
 </tr>
 <tr>
  <td>14
  </td>
  <td>Support
  Vector Classifier
  </td>
  <td>98,42
  </td>
  <td>0,64
  </td>
  <td>97,26
  </td>
  <td>0,44
  </td>
 </tr>
 <tr>
  <td>15
  </td>
  <td>Support
  Vector Classifier (NU Algorithm)
  </td>
  <td>99,58
  </td>
  <td>0,24
  </td>
  <td>99,89
  </td>
  <td>0,24
  </td>
 </tr>
 <tr>
  <td>16
  </td>
  <td>Arbitrary
  Kernel/Dissimilarity Based Classifier
  </td>
  <td>99,58
  </td>
  <td>0,44
  </td>
  <td>99,47
  </td>
  <td>0,00
  </td>
 </tr>
</tbody>
</table>
</div>
</center>

<center>
<div class="widetable">
<p class="body">Table
2. SSIM Parameter Estimation.</p>
<table>
<thead>
 <tr>
  <td>Parameter
  </td>
  <td>Value
  </td>
  <td>Accuracy (%)
  </td>
  <td>k
  </td>
  <td style="border:none; padding: 5px; text-align:center;"></td>
  <td>Parameter
  </td>
  <td>Value
  </td>
  <td>Accuracy (%)
  </td>
  <td>K
  </td>
 </tr>
</thead>
<tbody>
 <tr>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>1<br>1<br>1
  </td>
  <td>99,16
  </td>
  <td>1
  </td>
  <td style="border:none;padding: 5px; text-align:center;"></td>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>1<br>1<br>0
  </td>
  <td>100
  </td>
  <td>1
  </td>
 </tr>
 <tr>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>1<br>0<br>0
  </td>
  <td>100
  </td>
  <td>1
  </td>
  <td style="border:none;padding: 5px; text-align:center;"></td>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>0<br>1<br>1
  </td>
  <td>99,47
  </td>
  <td>1
  </td>
 </tr>
 <tr>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>0<br>1<br>0
  </td>
  <td>100
  </td>
  <td>1
  </td>
  <td style="border:none;padding: 5px; text-align:center;"></td>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>1<br>0<br>1
  </td>
  <td>99,47
  </td>
  <td>1
  </td>
 </tr>
 <tr>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>0<br>0<br>1
  </td>
  <td>98,05
  </td>
  <td>1
  </td>
  <td style="border:none;padding: 5px; text-align:center;"></td>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png"><br><img src="002_files/image019.png">
  </td>
  <td>2<br>2<br>1
  </td>
  <td>99,47
  </td>
  <td>1
  </td>
 </tr>
 </tbody>
</table>
</div>
</center>

<center>
<div class="widetable">
  <p class="body">Table
3. FSIM Parameter Estimation.</p>
<table>
<thead>
 <tr>
  <td>Parameter
  </td>
  <td>Value
  </td>
  <td>Accuracy (%)
  </td>
  <td>k
  </td>
 </tr>
</thead>
<tbody>
 <tr>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png">
  </td>
  <td>1<br>1
  </td>
  <td>98,84
  </td>
  <td>3
  </td>
 </tr>
 <tr>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png">
  </td>
  <td>1<br>0
  </td>
  <td>100
  </td>
  <td>2
  </td>
 </tr>
 <tr>
  <td><img src="002_files/image017.png"><br><img src="002_files/image018.png">
  </td>
  <td>0<br>1
  </td>
  <td>99,47
  </td>
  <td>3
  </td>
 </tr>
</tbody>
</table>
</div>
</center>

<p class="body">Theoretically in SSIM, <img src="002_files/image080.png">, <img src="002_files/image018.png"> and <img src="002_files/image019.png"> is defined as <img src="002_files/image020.png"> and <img src="002_files/image081.png">, but as a mathematical view, setting one of the <img src="002_files/image080.png">, <img src="002_files/image018.png"> and <img src="002_files/image019.png"> parameter to 0
means the impact of corresponding comparison function of that parameter will be
0, so the SSIM will be a combination of other comparison functions. <i>&#945;,
&#946;</i> and <i>&#947;</i> parameters were used for assigning the impact of
luminance, contrast and structural comparisons functions. It is clear in Table
2 that, the luminance or contrast comparison or both of them was enough for
butterfly species identification while using the structural comparison function
decreases the accuracy. In FSIM, <img src="002_files/image017.png"> and <img src="002_files/image018.png"> parameters of
FSIM were used to adjust the relative importance of PC and GM features. The
results in Table 3 show that the PC was a more important classification feature
than GM parameter for butterfly classification. Additionally different gradient
operators such as Scharr, Prewitt and Sobelis were employed and it was observed
that it did not change the accuracy. To date FSIM has been used for image
quality analysis and it is not used for classification.</p>

<p class="body">To assess the accuracy of employing SSIM [14, 15]
and FSIM [20] operators, the same dataset was compared with
peak-signal-to-noise ratio (PSNR) [19], scale invariant feature transform
(SIFT) [21], histogram comparison (HISTC) [22] and image spatiogram comparison
(SPATC) [23] and the obtained accuracies are listed in Table 4. In this
comparison, to minimize the effect of machine learning method, the
classifications were carried out by logistic linear classifier (LLC), linear
bayes classifier (LBC), k-nearest neighbor (kNN), nu-support vector classifier
(NUSVM) and arbitrary kernel/dissimilarity based classifier (AKBC) methods.</p>

<p class="body">Table 4 shows that SSIM and FSIM are better than
the other employed similarity methods for butterfly classification. The
accuracies obtained with the same dataset in previous studies were sorted in
Table 5.</p>

<center>
<div class="widetable">
  <p class="body">Table
4. Comparison of Similarity Methods.</p>
<table>
<thead>
 <tr>
  <td>Method
  </td>
  <td>Parameter</p>
  </td>
  <td>LLC</p>
  </td>
  <td>LBC</p>
  </td>
  <td>kNN</p>
  </td>
  <td>NUSVM</p>
  </td>
  <td>AKBC</p>
  </td>
 </tr>
</thead>
<tbody>
 <tr>
  <td >SSIM
  </td>
  <td>Accuracy (%)<br>STD
  </td>
  <td>100<br>0
  </td>
  <td>98,32<br>0,69
  </td>
  <td>99,37<br>0,24
  </td>
  <td>99,58<br>0,24
  </td>
  <td>99,58<br>0,44
  </td>
 </tr>
<tr>
  <td >FSIM
  </td>
  <td>Accuracy (%)<br>STD
  </td>
  <td>100<br>0
  </td>
  <td>99,26<br>0,29
  </td>
  <td>98,95<br>0,37
  </td>
  <td>99,79<br>0,29
  </td>
  <td>99,47<br>0
  </td>
 </tr>
 <tr>
  <td >SIFT
  </td>
  <td>Accuracy (%)<br>STD
  </td>
  <td>75,05<br>1,37
  </td>
  <td>73,16<br>1,18
  </td>
  <td>82,74<br>1,26
  </td>
  <td>75,79<br>1,53
  </td>
  <td>81,58<br>1,62
  </td>
 </tr>
 <tr>
  <td >HISTC
  </td>
  <td>Accuracy (%)<br>STD
  </td>
  <td>92,42<br>1,56
  </td>
  <td>95,37<br>0,69
  </td>
  <td>94,63<br>0,69
  </td>
  <td>89,05<br>2,51
  </td>
  <td>93,68<br>1,39
  </td>
 </tr>
 <tr>
  <td >SPATC
  </td>
  <td>Accuracy (%)<br>STD
  </td>
  <td>97,05<br>0,71
  </td>
  <td>96,84<br>1,23
  </td>
  <td>95,79<br>0,74
  </td>
  <td>95,16<br>0,78
  </td>
  <td>94,53<br>0,71
  </td>
 </tr>
 <tr>
  <td >PSNR
  </td>
  <td>Accuracy (%)<br>STD
  </td>
  <td>35,79<br>0,91
  </td>
  <td>85,37<br>2,12
  </td>
  <td>92,74<br>0,69
  </td>
  <td>87,58<br>1,42
  </td>
  <td>92,74<br>1,14
  </td>
 </tr>
</tbody>
</table>
</div>
</center>

<center>
<div class="widetable">
  <p class="body">Table
5. Obtained Accuracies.</p>
<table>
<thead>
 <tr>
  <td>Reference
  </td>
  <td>Feature
  Extraction
  </td>
  <td>Machine
  Learning
  </td>
  <td>Accuracy
  (%)
  </td>
 </tr>
</thead>
<tbody>
 <tr>
  <td>in [3]
  </td>
  <td>Gabor
  Filters
  </td>
  <td>ELM
  </td>
  <td>97
  </td>
 </tr>
 <tr>
  <td>in [4]
  </td>
  <td>GLCM
  </td>
  <td>MLR
  </td>
  <td>96,3
  </td>
 </tr>
 <tr>
  <td>in [5]
  </td>
  <td>GLCM
  </td>
  <td>ANN
  </td>
  <td>92.85
  </td>
 </tr>
 <tr>
  <td>in [6]
  </td>
  <td>LBP
  </td>
  <td>ELM
  </td>
  <td>98.25
  </td>
 </tr>
 <tr>
  <td>in [6]
  </td>
  <td>GLCM
  </td>
  <td>ELM
  </td>
  <td>96.45
  </td>
 </tr>
 <tr>
  <td>in this
  study
  </td>
  <td>SSIM
  </td>
  <td>LLC
  </td>
  <td>100
  </td>
 </tr>
 <tr>
  <td>in this
  study
  </td>
  <td>FSIM
  </td>
  <td>LLC
  </td>
  <td>100
  </td>
 </tr>
</tbody>
</table>
</div>
</center>

<p class="body">It is apparent from Table 5 that the obtained
classification accuracy is higher while employing similarity indexes instead of
texture methods. The proposed approach has a number of attractive features: it
needs lower computational complexity and time requirements compare with texture
methods. A possible explanation for the higher classification accuracy obtained
while employing SSIM and FSIM this might be that their computational simplicity
and power of distinguishing image. </p>

<p class="body">The authors strongly suggest that employing
similarity by prototypes is a better approach than using conventional
diagnostic methods for identification and other image texture analysis methods.
Since employing it requires less effort and attention than time consuming and
attention-seeking conventional diagnostic methods [6].  Furthermore, employing
prototypes is a natural human learning mechanism; therefore the proposed method
can be easily enlarged to include other species or families.</p>

<h4>3. Conclusion</h4>

<p class="body">The present study was designed to determine the
effect of employing the similarity indexes SSIM and FSIM to identify the
butterfly species instead of texture methods, which are complex and time
consuming methods. The proposed method is depends of human learning
(prototypes) and vision system (SSIM and FSIM), therefore it is a natural way
of classification of butterfly species. The classification accuracies of using
them are higher than the results obtained in the literature. Also, these
results were compared with results obtained from employing PSNR, SIFT, HISTC
and SPATC similarity methods. Additionally, the accuracy results were showing
that the butterfly identification is depended on the luminance or contrast
comparison while using the structural comparison function decreases the
accuracy in SSIM. Similarly, in FSIM, the PC was more important than GM
parameter and gradient operators did not change the accuracy. To our knowledge,
there isn’t any study in the literature to identify the butterfly species by
using similarity methods. The results of this study show/indicate that SSIM and
FSIM similarity operators were very successful feature extraction methods for
butterfly identification and the obtained classification accuracy is 100%, when
the classification was carried out with logistic linear classifier. The most
obvious finding to emerge from this study is that the proposed method can be
used with enlarged datasets by adding a prototype image for each new butterfly
species and can be used in real time application depend on its simplicity.</p>

<h4 id="references">References</h4>
<div class="ref">
<p class="body">[1] L. Kayci, “Erek
  Da&#287;&#305; (Van) Papilionoidea ve Hesperioidea Ekolojisi ve Faunas&#305;
  Üzerine Ara&#351;t&#305;rmalar (Lepidoptera),” <i>Priamus Suppl.</i>, vol. 6,
  pp. 1-47, 2007.</p>

<p class="body">[2] P. Herbert and R.
  Gregory, “The Promise of DNA Barcoding for Taxonomy,” <i>Syst. Biology</i>,
  vol. 54, no. 5, pp. 852-859, Jul. 2005. <a href="http://dx.doi.org/10.1080/10635150500354886" target="_blank" class="body-link">View Article</a></p>

<p class="body">[3] L. Kayci, Y. Kaya and T.
  Ramazan, “A Computer Vision System for the Automatic Identification of
  Butterfly Species via Gabor-Filter-Based Texture Features and Extreme
  Learning Machine: GF+ELM,” <i>TEM J.</i>, vol. 2, no. 1, pp.13-20, Nov. 2013. <a href="http://www.temjournal.com/documents/vol2no1/pdf/A%20computer%20vision%20system%20for%20the%20automatic%20identification%20of%20butterfly%20species%20via%20Gabor-filter-based%20texture%20features%20and%20extreme%20learning%20machine%20GF+ELM.pdf" target="_blank" class="body-link">View Article</a></p>

<p class="body">[4] L. Kayci and Y. Kaya, “A
  Vision System for Automatic Identification of Butterfly Species Using a
  Grey-Level Co-occurrence Matrix and Multinomial Logistic Regression,” <i>Zoology
  in the Middle East</i>, vol. 60, no. 1, pp. 57-64, Feb. 2014. <a href="http://dx.doi.org/10.1080/09397140.2014.892340" target="_blank" class="body-link">View Article</a></p>

<p class="body">[5] Y. Kaya and L. Kayci,
  “Application of Artificial Neural Network for Automatic Detection of Butterfly
  Species Using Color and Texture Features,” <i>Visual Comput.</i>, vol. 30,
  no. 1, pp. 71-79, Jan. 2014. <a href="http://dx.doi.org/10.1007/s00371-013-0782-8" target="_blank" class="body-link">View Article</a></p>

<p class="body">[6] Y. Kaya, L. Kayc&#305;,
  R. Tekin, and Ö.F. Ertu&#287;rul, “Evaluation of Texture Features for
  Automatic Detecting Butterfly Species Using Extreme Learning Machine,” <i>J.
  of Experimental &amp; Theoretical Artificial Intell.</i>, vol. 26, no. 2, pp.
  267-281, Jan. 2014. <a href="http://dx.doi.org/10.1080/0952813X.2013.861875" target="_blank" class="body-link">View Article</a></p>

<p class="body">[7] F.G. Ashby and WT Maddox,
  “Relation Between Prototype, Exemplar and Decision Bound Models of
  Categorization,” <i>J. of Math. Psychology</i>, vol. 37, no. 3, pp.372-400,
  Sep. 1993. <a href="http://dx.doi.org/10.1006/jmps.1993.1023" target="_blank" class="body-link">View Article</a></p>

<p class="body">[8] W.T. Maddox and F.G. Ashby,
  “Comparing Decision Bound and Exemplar Models of Categorization,” <i>Perception
  &amp; Psychophysics</i>, vol. 53, no. 1, pp. 49-70, Jan. 1993. <a href="http://dx.doi.org/10.3758/BF03211715" target="_blank" class="body-link">View Article</a></p>

<p class="body">[9] F. Leon, “Generalized
  Nearest Neighbor Method for the Classification of Composite Concepts,” <i>IEEE
  2nd Int. Conf. on Intell. Comput. Commun. and Process.</i>, ICCP, pp. 23-28,
  (2006). <a href="http://florinleon.byethost24.com/papers/0614.pdf" target="_blank" class="body-link">View Article</a></p>

<p class="body">[10] D.L. Medin, B.H. Ross,
  and A.B. Markman, “<i>Cognitive Psychology,</i>” Wiley, 2005. <a href="http://www.amazon.com/Cognitive-Psychology-Douglas-Medin-PhD/dp/0471458201" target="_blank" class="body-link">View Book</a></p>

<p class="body">[11] D.N. Osherson and E. Smith,
  “On the Adequacy of Prototype Theory as a Theory of Concepts,” <i>Cognition,</i>
  vol. 9, no. 1, pp. 35-58, 1981. <a href="http://dx.doi.org/10.1016/0010-0277(81)90013-5" target="_blank" class="body-link">View Article</a></p>

<p class="body">[12] E. Smith and D.N. Osherson,
  “Conceptual Combination with Prototype Concepts,” <i>Cognitive Sci.</i>, vol.
  8, no. 4, pp. 337-361, Oct. 1984. <a href="http://dx.doi.org/10.1207/s15516709cog0804_2" target="_blank" class="body-link">View Article</a></p>

<p class="body">[13] S. Garcia, J. Derrac, J.
  Luengo, and F. Herrera, “A First Approach to Nearest Hyperrectangle Selection
  by Evolutionary Algorithms,” <i>Ninth Int. Conf. on Intell. Syst. Design and
  Appl.</i>, pp. 517-522, 2009. <a href="http://dx.doi.org/10.1109/ISDA.2009.238" target="_blank" class="body-link">View Article</a></p>

<p class="body">[14] Z. Wang, E. P. Simoncelli,
  and A. C. Bovik, “Multiscale Structural Similarity for Image Quality
  Assessment,” <i>Signals, Syst. and Comput., 2004. Conf. Record of the Thirty-Seventh
  Asilomar Conf,</i> vol. 2, pp. 1398-1402, Nov. 2003. <a href="http://dx.doi.org/10.1109/ACSSC.2003.1292216" target="_blank" class="body-link">View Article</a></p>

<p class="body">[15] Z. Wang, A. C. Bovik, H.
  R. Sheikh, and E. P. Simoncelli, “Image Quality Assessment: From Error Visibility
  to Structural Similarity,” <i>IEEE Trans. on Image Process.</i>, vol. 13, no.
  4, pp. 600-612, Apr. 2004. <a href="http://dx.doi.org/10.1109/TIP.2003.819861" target="_blank" class="body-link">View Article</a></p>

<p class="body">[16] Z. Wang, Q. Li, and X. Shang,
  “Perceptual Image Coding Based on A Maximum of Minimal Structural,” <i>Int. Conf. on Image Process.</i>, ICIP 2007: pp. II-121– II-124, 2007. <a href="http://dx.doi.org/10.1109/ICIP.2007.4379107" target="_blank" class="body-link">View Article</a></p>

<p class="body">[17] D. M. Rouse and S. S. Hemami,
  “Analyzing the Role of Visual Structure in the Recognition of Natural Image
  Content with Multi-Scale SSIM Similarity Criterion,” <i>IEEE Western New York
  Image Process. Workshop,</i> WNYIP, 2007. <a href="http://dx.doi.org/10.1117/12.768060" target="_blank" class="body-link">View Article</a></p>

<p class="body">[18] G. Fan, Z. Wang, and J. Wanga,
  “CW-SSIM Kernel Based Random Forest for Image Classification,” <i>Visual
  Commun. and Image Process.</i>, vol. 7744, Aug. 2010. <a href="http://dx.doi.org/10.1117/12.863528" target="_blank" class="body-link">View Article</a></p>

<p class="body">[19] A. Horé and D. Ziou, “Image
  Quality Metrics: PSNR vs. SSIM,” <i>IEEE 2010, Int. Conf. on Pattern
  Recognition</i>, 2010. <a href="http://dx.doi.org/10.1109/ICPR.2010.579" target="_blank" class="body-link">View Article</a></p>

<p class="body">[20] L. Zhang, L. Zhang, X. Mou,
  and D. Zhang, “FSIM: A Feature Similarity Index for
  Image Quality Assessment,” <i>IEEE Trans. on Image Process.</i>, vol. 20, no,
  18, pp. 2378 – 2386, Jan. 2011. <a href="http://dx.doi.org/10.1109/TIP.2011.2109730" target="_blank" class="body-link">View Article</a></p>

<p class="body">[21] D. G. Lowe, “Distinctive
  Image Features from Scale-Invariant Keypoints,” <i>Int. J. of Comput. Vision</i>,
  Nov. 2004. <a href="http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94" target="_blank" class="body-link">View Article</a></p>

<p class="body">[22] V.D. Weken, M. Nachtegael,
  and E. Kerre, “Some New Similarity Measures for
  Histograms,” <i>Fourth Indian Conf. on Comput. Vision, Graphics &amp; Image
  Process.</i>, 2004. <a href="http://www.cse.iitb.ac.in/sharat/icvgip.org/icvgip2004/proceedings/ip2.6_194.pdf" target="_blank" class="body-link">View Article</a></p>

<p class="body">[23] C. O. Conaire, N. E. O’Connor,
  and A. F. Smeaton, “An Improved Spatiogram Similarity Measure For Robust
  Object Localisation,” <i>Acoustics, Speech and Signal Process.</i>, ICASSP 2007. <a href="http://dx.doi.org/10.1109/ICASSP.2007.366096" target="_blank" class="body-link">View Article</a></p>
</div> <!-- REF -->

  </div> <!-- INDENT -->
  </div> <!-- Main Content -->
</div>
</div>

  <footer>
<div class="grid">
  <div class="unit unit-s-1 unit-s-1-3 unit-m-1-3 unit-l-1-3">
    <div class="unit-spacer">
      <ul class="footer-links">
        <li><a href="http://avestia.com" class="body-link">Avestia Publishing</a></li>
        <li><a href="http://avestia.com/journals" class="body-link">Journals</a></li>
        <li><script>var refURL = window.location.protocol + "//" + window.location.host + window.location.pathname; document.write('<a href="http://international-aset.com/feedback/?refURL=' + refURL+'">Feedback</a>');</script></li>
        <li><a href="http://avestia.com/terms" class="body-link">Terms of Use</a></li>
        <li><a href="../sitemap" class="body-link">Sitemap</a></li>
      </ul>
    </div>
  </div>

  <div class="unit unit-s-1 unit-s-1-3 unit-m-1-3 unit-l-1-3">
    <div class="unit-spacer">
      <p class="body">
        Avestia Publishing,<br>
        International ASET Inc.<br>
        Unit 417, 1376 Bank St.<br>
        Ottawa, ON, Canada, K1H 7Y3<br>
        +1 613-695-3040<br>
        <a href="mailto:info@avestia.com" class="body-link">info@avestia.com</a>
      </p>
    </div>
  </div>

  <div class="unit unit-s-1 unit-s-1-3 unit-m-1-3 unit-l-1-3">
    <div class="unit-spacer social">
    <form class="subscribe" action="../register.php" method="post">
            <span id="sprytextfield2"><input name="email" type="text" id="email" value="Join our mailing list"
              onblur="if (this.value == '') {this.value = 'Join our mailing list';}"
        onfocus="if (this.value == 'Join our mailing list') {this.value = '';}" ></span>
      <input type="submit" name="submit" value="Submit" class="form_button" />
        </form>
        
      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://www.facebook.com/pages/International-Academy-of-Science-Engineering-and-Technology/207827708283" target="blank" title="International ASET Inc. Facebook Page">
          <img src="../img/fb.png" border="0" onmouseover="this.src='../img/fb-hover.png'" onmouseout="this.src='../img/fb.png'">
        </a>
      </div>

      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://twitter.com/ASET_INC" target="blank" title="International ASET Inc. Twitter">
          <img src="../img/twitter.png" border="0" onmouseover="this.src='../img/twitter-hover.png'" onmouseout="this.src='../img/twitter.png'">
        </a>
      </div>

      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://www.linkedin.com/company/1169039" target="blank" title="International ASET Inc. LinkedIn">
          <img src="../img/linkedin.png" border="0" onmouseover="this.src='../img/linkedin-hover.png'" onmouseout="this.src='../img/linkedin.png'">
        </a>
      </div>

      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://plus.google.com/u/0/+International-aset/posts" target="blank" title="International ASET Inc. Google+ Page">
          <img src="../img/google.png" border="0" onmouseover="this.src='../img/google-hover.png'" onmouseout="this.src='../img/google.png'">
        </a>
      </div>

      <p class="body">© Copyright 2015, International ASET Inc. – All Rights Reserved.</p>
    </div>
  </div>

</div>
</footer>
</div>

 <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
    <script src="../js/cbpAnimatedHeader.min.js"></script>
    <script src="../js/SpryValidationSelect.js" type="text/javascript"></script>

    <script src="../js/SpryValidationTextField.js" type="text/javascript"></script>

    <script src="../js/SpryValidationConfirm.js" type="text/javascript"></script>

    <script src="../js/SpryValidationCheckbox.js" type="text/javascript"></script>
    <script src="../js/SpryValidationTextarea.js" type="text/javascript"></script>

<script src="../js/classie.js"></script>
<script src="../js/jquery.easing.js"></script>
<script src="../js/jquery.mousewheel.js"></script>
<script defer src="../js/demo.js"></script>
<script type="text/javascript" src="../css/animate.min.css"></script>
<script type="text/javascript" src="../js/jnav.js"></script>

<script type="text/javascript">
<!--
var sprytextfield1 = new Spry.Widget.ValidationTextField("sprytextfield1", "none");
var sprytextfield2 = new Spry.Widget.ValidationTextField("sprytextfield2", "email");
var sprytextfield3 = new Spry.Widget.ValidationTextField("sprytextfield3");
var sprytextfield4 = new Spry.Widget.ValidationTextField("sprytextfield4");
var spryselect2 = new Spry.Widget.ValidationSelect("spryselect2", {invalidValue:"-1"});
var sprytextarea1 = new Spry.Widget.ValidationTextarea("sprytextarea1");
var sprytextfield5 = new Spry.Widget.ValidationTextField("sprytextfield5");
var sprytextfield6 = new Spry.Widget.ValidationTextField("sprytextfield6");
//-->
</script>

    <script type="text/javascript">
/*
  Slidemenu
*/
(function() {
  var $body = document.body
  , $menu_trigger = $body.getElementsByClassName('menu-trigger')[0];

  if ( typeof $menu_trigger !== 'undefined' ) {
    $menu_trigger.addEventListener('click', function() {
      $body.className = ( $body.className == 'menu-active' )? '' : 'menu-active';
    });
  }

}).call(this);
</script>

<script type="text/javascript">
/*
  Slidemenu
*/
(function() {
  var $body = document.body
  , $menu_trigger = $body.getElementsByClassName('menu-trigger-1')[0];

  if ( typeof $menu_trigger !== 'undefined' ) {
    $menu_trigger.addEventListener('click', function() {
      $body.className = ( $body.className == 'menu-active' )? '' : 'menu-active';
    });
  }

}).call(this);
</script>
</body>
</html>
